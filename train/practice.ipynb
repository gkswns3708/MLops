{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import timm\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/home/hj/Study/MLops/Test_Data|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Base Implement Model to training\n",
    "    \"\"\"\n",
    "    def __init__(self, class_n, rate=0.1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        self.classifier1 = nn.Linear(1000,25)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        output = self.dropout(self.classifier1(output))# dropout 조심.\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transform = {\n",
    "    \"train_Filp_transform\": A.Compose(\n",
    "        [\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=1.0),\n",
    "                    A.VerticalFlip(p=1.0),\n",
    "                    A.RandomRotate90(p=1.0),\n",
    "                ],\n",
    "                p=0.75,\n",
    "            ),\n",
    "            A.RandomBrightness(p=0.5, limit=(-0.2, 0.25)),\n",
    "            A.RandomContrast(p=0.5, limit=(-0.25, 0.25)),\n",
    "            ToTensorV2(p=1.0),  # dtype float32, transpose 한번에\n",
    "        ]\n",
    "    ),\n",
    "    \"train_deault_transform\": A.Compose([ToTensorV2(p=1.0)]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, dataset_df, transform=None):\n",
    "        super().__init__()\n",
    "        assert transform is not None, \"Set the transform on train set\"\n",
    "        self.transform = transform\n",
    "        self.dataset_df = dataset_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO : Image Path를 csv 파일에 추가하는게 좋은 선택지 같음.\n",
    "        self.dataset_df['image_path']\n",
    "        image = cv2.imread(self.dataset_df['image_path'].iloc[idx])\n",
    "        # TODO : TOTensorV2를 쓰면 numpy 채널 축도 변하고 ToTensor의 기능을 포함함.\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=image)['image'].float()\n",
    "        return image, torch.tensor(self.dataset_df['label'].iloc[idx])\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.dataset_df['label'].iloc[:]\n",
    "\n",
    "class CropDataset():\n",
    "    def __init__(self, transform=None, default_transform=None, config=None):\n",
    "        super().__init__()\n",
    "        # TODO : 다양한 assert문 utils로 추가해놓기 (params : variable name)\n",
    "        assert transform is not None, \"Set the transform on train set\"\n",
    "        assert default_transform is not None, \"Set the default transform\"\n",
    "\n",
    "        self.transform = transform\n",
    "        self.default_transform = default_transform\n",
    "        self.dir_path = os.path.dirname(config['Prepared_Data_Path'])\n",
    "        self.df_path = os.path.join(self.dir_path, 'train.csv')\n",
    "        self.img_dir_path = config['Prepared_Data_Path']\n",
    "\n",
    "        self.dataset_df = pd.read_csv(os.path.join(config['Prepared_Csv_Path'], 'train.csv'))\n",
    "        # TODO : Class Imbalance 문제를 해결하기 위해 각 class weight를 지정하는 코드 Cross_Entropy를 사용할 때 사용할 듯\n",
    "        # self.class_weight = self._get_class_weight() # 학습 고도화를 위한 각 class Imbalance 문제를 위한 코드\n",
    "\n",
    "\n",
    "    def split_validation(self, valid_split_ratio):\n",
    "        # TODO : Stratify의 처리가 제대로되는지 확인하기\n",
    "        df_train, df_val = train_test_split(self.dataset_df, test_size=valid_split_ratio, random_state=42, stratify=self.dataset_df['label'].to_numpy())\n",
    "        train_dataset = BaseDataset(df_train, transform=self.transform)\n",
    "        val_dataset = BaseDataset(df_val, transform=self.default_transform)\n",
    "        return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "image_dir = sorted(glob(os.path.join(test_dir, '*/*.jpg')))\n",
    "train_dataset, val_dataset  = CropDataset()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41dac6b197742934d933ac5beeed27df1f48255da5451d7725efde7c8f37fd42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MLops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
